# 컨슈머 API

``` java
package com.example;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

public class SimpleConsumer {
	private final static Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
	private final static String TOPIC_NAME = "test";
	private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
	
	public static void main(String[] args) {
		Runtime.getRuntime().addShutdownHook(new ShutdownThread());
	
		Properties configs = new Properties();
		configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
		configs.put(ConsumerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
		configs.put(ConsumerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
		configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
		consumer.subscribe(Arrays.asList(TOPIC_NAME), new RebalanceListener());

		try {
			while (true) {
				ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
				for (ConsumerRecord<String, String> record: records) {
					logger.info("{}", record);
				}
			}
		} catch (WakeupException e) {
			logger.warn("Wakeup consumer");
			// 리소스 종료
		} finally {
			consumer.close();
		}
	}
	
	private static class RebalanceListener implements ConsumerRebalanceListener {
		public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
			logger.warn("Partitions are assigned");
		}
		
		public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
			logger.warn("Partitions are revoked");
			consumer.commitSync(currentOffsets);
		}
	}
	
	static class ShutdownThread extends Thread {
		public void run() {
			logger.info("Shutdown hook");
			consumer.wakeup();
		}
	}
}
```
- 브로커에 적재된 데이터를 가져와서 필요한 처리를 한다. 
- 컨슈머를 운영하는 방법은 크게 2가지가 있다. 컨슈머 그룹을 운영하기 / 토픽의 특정 파티션만 구독하는 컨슈머를 운영하기
- 컨슈머 그룹의 컨슈머가 토픽을 구독해서 데이터를 가져갈 때, 1개의 파티션은 최대 1개의 컨슈머에 할당 가능하다. 1개 컨슈머는 여러 개의 파티션에 할당될 수 있다. 그래서 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 한다. 
  - e.g. 3개 파티션 가진 토픽을 효과적으로 처리하기 위해서는 3개 이하의 컨슈머로 이뤄진 컨슈머 그룹으로 운영해야 한다. 만약 4개의 컨슈머라면 1개의 컨슈머는 파티션을 할당받지 못하고 유휴 상태로 남게 된다. 
- 컨슈머 그룹의 컨슈머에 장애가 발생하면, 그 컨슈머에 할당된 파티션은 다른 컨슈머에 소유권이 넘어간다. (rebalancing)
- 리밸런싱은 컨슈머가 추가되는 상황에, 컨슈머가 제외되는 상황에 일어난다. 
- 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 commit을 통해 기록한다. 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 카프카 브로커 내부에서 사용되는 내부 토픽(__consumer_offsets)에 기록된다.

- 오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수 있다. 기본 옵션은 poll() 메서드가 수행될 때 일정 간격마다 오프셋을 커밋하도록 enable.auto.commit=true로 설정되어 있다.
  - 비명시적 오프셋 커밋: 일정 간격마다 자동 커밋 (auto.commit.interval.ms 조정)
  - poll() 메서드를 호출할 때 커밋을 수행하므로 코드상에서 따로 커밋 관련 코드를 작성할 필요가 없다.
  - poll() 메서드 호출 이후에 리밸런싱 또는 컨슈머 강제종료 발생 시 데이터 중복 또는 유실될 수 있는 가능성이 있다. 중복이나 유실을 허용하지 않는 서비스라면 자동 커밋을 사용해선 안 된다. 
- 명시적 오프셋 커밋: poll() 메서드 호출 이후에 데이터 처리가 완료되고 commitSync() 메서드 호출
  - commitSync() 메서드는 poll() 메서드를 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행한다.
  - commitSync() 메서드는 브로커에 커밋 요청을 하고 응답 받기까지 blocking이다. 이 때문에 commitAsync() 메서드를 사용할 수 있는데, 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 중복 처리가 발생할 수 있다.

- 컨슈머는 poll() 메서드를 통해 레코드를 받는다. 하지만 poll() 메서드 호출 시점에 데이터를 가져오는 게 아니다. 컨슈머 애플리케이션을 실행하면 내부에서 Fetcher 인스턴스가 생성되어 poll()을 호출하기 전에 미리 레코드들을 내부 큐로 가져온다. 이후에 사용자가 명시적으로 poll()을 호출하면 컨슈머는 내부 큐에 있는 레코드들을 반환받아 처리를 수행한다. 
- 컨슈머 설정 필수 옵션
  - bootstrap.servers: 브로커 호스트 이름:포트 1개 이상. 2개 이상 입력해 일부 브로커에 이슈가 발생하더라도 접속에 이슈가 없도록 설정 가능하다.
  - key.deserialize
  - value.deserializer

- 컨슈머 설정 선택 옵션
  - group.id: 컨슈머 그룹 아이디. 기본값은 null.
  - auto.offset.reset: 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택. 이미 컨슈머 오프셋이 있으면 무시됨. [latest(가장 최근), earlist(가장 오래 전), none(컨슈머 그룹이 커밋한 기록을 찾아봐서 없으면 오류, 있으면 기존 커밋 기록 이후 오프셋부터 읽음)] 중 1개. 기본값은 latest.
  - enable.auto.commit: 자동 커밋으로 할지 수동 커밋으로 할지 선택. 기본값은 true.
  - auto.commit.interval.ms: 자동 커밋(enable.auto.commit=true)일 경우 오프셋 커밋 간격 지정. 기본값은 5000(5s).
  - max.poll.records: poll() 메서드를 통해 반환되는 레코드 개수 지정. 기본값은 500.
  - session.timeout.ms: 이 시간 내에 heartbeat를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱 한다. 보통 heartbeat 시간 간격의 3개로 설정한다. 기본값은 10000(10s).
  - heartbeat.interval.ms: heartbeat를 전송하는 시간 간격. 기본값은 3000(3s).
  - max.poll.interval.ms: poll() 메서드를호출하는 간격의 최대 시간. poll() 호출 후 데이터 처리에 시간이 너무 많이 걸리는 경우 비정상으로 판단하고 리밸런싱 한다. 기본값은 300000(5m).
  - isolation.level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용. [read_committed, read_uncommitted] 중 1개. 기본값은 read_uncommitted.
 
- 데이터를 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다. 중복 처리하지 않기 위해선 리밸런스 발생 시 처리한 데이터를 기준으로 커밋을 시도해야 한다.  
  ConsumerRebalanceListener 인터페이스의 onPartitionAssigned()는 리밸런스가 끝난 뒤 파티션이 할당 완료되면 호출되고, onPartitionRevoked()는 리밸런스가 시작되기 직전에 호출된다. 그래서 마지막으로 처리한 레코드를 기준으로 커밋을 하기 위해서 onPartitionRevoked()에 커밋을 구현할 수 있다.
- 컨슈머는 subscribe() 외에도 assign()를 사용해 직접 파티션을 명시적으로 할당 받을 수 있다. subscribe()를 사용할 때와 다르게 직접 컨슈머가 특정 토픽, 특정 파티션에 할당되므로 리밸런싱 과정이 없다.
- 컨슈머 애플리케이션은 안전하게 종료되어야 한다. 정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때까지 컨슈머 그룹에 남게 된다. 이로 인해 실제로는 종료되었지만 더는 동작을 하지 않는 컨슈머가 존재하기 때문에 파티션의 데이터는 소모되지 못하고 컨슈머 랙이 늘어나게 된다. 컨슈머 랙이 늘어나면 데이터 처리 지연이 발생한다.  
- KafkaConsumer의 wakeup()을 사용하여 컨슈머를 안전하게 종료할 수 있다. poll()을 통해 지속적으로 레코드들을 받아 처리하다가 wakeup()가 호출되면 다음 poll()이 호출되었을 때 WakeupException 예외가 발생한다. 예외를 받은 뒤에는 데이터 처리를 위해 사용한 자원들을 해제하면 된다. 마지막에는 consumer.close()를 호출하여 카프카 클러스터에 컨슈머가 안전하게 종료하였음을 명시적으로 알려주면 종료가 완료되었다고 볼 수 있다.  
  그러면 wakeup()는 어디서 호출되어야 할까? 자바 애플리케이션의 경우 운영체제로부터 종료 요청을 받으면 실행하는 스레드인 shutdown hook을 구현하여 여기서 wakeup()를 호출하면 된다.



